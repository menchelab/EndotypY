"""
Statistical significance testing for KL divergence in hierarchical clustering.

This module provides hypothesis tests to determine whether observed KL divergence
values are statistically significant, indicating meaningful deviation from uniformity
or independence between distributions.

Final Strategy (Benjamini-Hochberg on Global KL):
- Uses GLOBAL KL divergence D_KL(Node || Root) for significance testing
- Applies Benjamini-Hochberg (FDR) correction across all nodes
- The Are_Features_Dependent column is the definitive result for decomposition
- Original tests preserved for informational/diagnostic purposes

Tests Implemented:
1. Benjamini-Hochberg FDR Correction (PRIMARY - used for decomposition)
   - Controls False Discovery Rate across all nodes
   - Uses global KL divergence from root distribution
   - Final decision: Are_Features_Dependent column

2. Feature independence test (with Bonferroni correction) - INFORMATIONAL
   - Tests if features are independent (H0) vs. dependent (H1)
   - Conservative (corrects for multiple testing)
   - Kept for diagnostics only

3. Feature independence test (without Bonferroni correction) - INFORMATIONAL
   - Less conservative than Bonferroni
   - Kept for diagnostics only

4. Deviation from zero test (optional, empirical) - INFORMATIONAL
   - Tests if node is an outlier compared to other nodes
   - Uses standard deviation threshold (e.g., 2σ)
   - Data-driven approach
"""

import numpy as np
import pandas as pd
from scipy.stats import chi2
from typing import Dict, Union, Optional, Tuple, List
from statsmodels.stats.multitest import multipletests


def test_feature_independence_conservative(
    kl_divergence_from_uniform: float,
    number_of_leaves_in_node: int,
    number_of_features: int,
    significance_level_alpha: float = 0.05,
    number_of_tests_for_correction: Optional[int] = None,
) -> Dict[str, Union[float, bool, str]]:
    """
    (Informational Test) Test if features are independent using Bonferroni correction.
    """
    # Calculate chi-squared statistic
    chi2_statistic = 2 * number_of_leaves_in_node * kl_divergence_from_uniform

    # Degrees of freedom
    degrees_of_freedom = number_of_features

    # Calculate p-value (survival function = 1 - CDF)
    p_value = chi2.sf(chi2_statistic, df=degrees_of_freedom)

    # Apply Bonferroni correction if requested
    if (
        number_of_tests_for_correction is not None
        and number_of_tests_for_correction > 0
    ):
        alpha_used = significance_level_alpha / number_of_tests_for_correction
        correction_note = f"Bonferroni-corrected ({significance_level_alpha}/{number_of_tests_for_correction})"
    else:
        alpha_used = significance_level_alpha
        correction_note = "No correction"

    # Determine if features are dependent
    are_features_dependent = p_value < alpha_used

    return {
        "test_name": "Feature Independence Test (Conservative with Bonferroni)",
        "null_hypothesis": "Features are independent (random, no associations)",
        "independence_conservative_chi2_statistic": chi2_statistic,
        "independence_conservative_degrees_of_freedom": degrees_of_freedom,
        "independence_conservative_p_value": p_value,
        "independence_conservative_alpha_used": alpha_used,
        "independence_conservative_alpha_correction": correction_note,
        "independence_conservative_are_features_dependent": are_features_dependent,
        "independence_conservative_result": "Features Dependent"
        if are_features_dependent
        else "Features Independent",
    }


def test_feature_independence_liberal(
    kl_divergence_from_uniform: float,
    number_of_leaves_in_node: int,
    number_of_features: int,
    significance_level_alpha: float = 0.05,
) -> Dict[str, Union[float, str, bool]]:
    """
    (Informational Test) Test if features are independent without multiple testing correction.
    """
    # Calculate chi-squared statistic
    chi2_statistic = 2 * number_of_leaves_in_node * kl_divergence_from_uniform

    # Degrees of freedom
    degrees_of_freedom = number_of_features

    # Calculate p-value (survival function = 1 - CDF)
    p_value = chi2.sf(chi2_statistic, df=degrees_of_freedom)

    # Determine if features are dependent
    are_features_dependent = p_value < significance_level_alpha  # Reject H0 → Dependent

    return {
        "test_name": "Feature Independence Test (Liberal, No Bonferroni)",
        "null_hypothesis": "Features are independent (no associations)",
        "independence_liberal_kl_divergence": kl_divergence_from_uniform,
        "independence_liberal_chi2_statistic": chi2_statistic,
        "independence_liberal_degrees_of_freedom": degrees_of_freedom,
        "independence_liberal_p_value": p_value,
        "independence_liberal_alpha_used": significance_level_alpha,
        "independence_liberal_are_features_dependent": are_features_dependent,
        "independence_liberal_result": "Features Dependent" if are_features_dependent else "Features Independent",
    }


def kl_divergence_deviation_from_zero_test(
    kl_divergence: float,
    all_kl_divergences: np.ndarray,
    num_std: float = 2.0,
) -> Dict[str, Union[float, bool, str]]:
    """
    (Informational Test) Test if KL divergence is a significant outlier.
    """
    std_kl = np.std(all_kl_divergences) if len(all_kl_divergences) > 0 else 0.0
    z_score = kl_divergence / std_kl if std_kl > 0 else 0.0
    threshold = num_std * std_kl
    is_significant = abs(z_score) > num_std

    return {
        "test_name": f"KL Divergence Deviation from Zero Test ({num_std}σ)",
        "kl_divergence": kl_divergence,
        "z_score": z_score,
        "is_significant": is_significant,
        "result": "Significant" if is_significant else "Not Significant",
    }


def apply_multiple_testing_correction(
    p_values: list,
    alpha: float = 0.05,
    method: str = 'fdr_bh'
) -> tuple[list[bool], list[float]]:
    """
    Apply a multiple testing correction procedure to a list of p-values.

    Args:
        p_values: A list of p-values.
        alpha: The significance level (e.g., for FDR).
        method: The correction method to use (from statsmodels).

    Returns:
        A tuple containing (rejected, pvals_corrected).
    """
    if not p_values:
        return [], []

    rejected, pvals_corrected, _, _ = multipletests(
        p_values, alpha=alpha, method=method
    )
    return rejected, pvals_corrected


def perform_all_informational_tests(
    kl_div_global: float,
    leaf_count: int,
    total_number_of_features: int,
    significance_level_alpha: float = 0.05,
) -> Dict[str, Dict]:
    """
    Performs all older tests for informational purposes only.
    """
    # Liberal test is the basis for raw p-value
    liberal_results = test_feature_independence_liberal(
        kl_divergence_from_uniform=kl_div_global,
        number_of_leaves_in_node=leaf_count,
        number_of_features=total_number_of_features,
        significance_level_alpha=significance_level_alpha,
    )

    return {
        "liberal": liberal_results,
    }


def annotate_nodes_with_statistical_significance(
    nodes_statistics_dataframe: pd.DataFrame,
    total_number_of_features: int,
    significance_level_alpha: float = 0.05,
    correction_method: str = 'fdr_bh',
) -> pd.DataFrame:
    """
    Performs significance tests using Benjamini-Hochberg for the final decision.

    This function uses the Benjamini-Hochberg procedure to control the False Discovery Rate
    and determine the final 'Are_Features_Dependent' column.

    Args:
        nodes_statistics_dataframe: DataFrame with REQUIRED columns:
            - 'kl_divergence_global': KL divergence value for each node vs. the root.
            - 'leaf_count': Number of leaves (samples) in each node.
        total_number_of_features: Total number of features in the dataset.
        significance_level_alpha: Significance level (FDR rate) for correction.
        correction_method: Method for multiple testing correction.

    Returns:
        An annotated DataFrame. The key column for decomposition is 'Are_Features_Dependent'.
    """
    testable_nodes = nodes_statistics_dataframe[
        nodes_statistics_dataframe["kl_divergence_global"].notna()
    ].copy()

    # --- Pass 1: Gather all raw p-values from the global KL divergence ---
    raw_p_values = []
    for node_id, row in testable_nodes.iterrows():
        kl_div = row["kl_divergence_global"]
        leaf_count = row["leaf_count"]
        chi2_statistic = 2 * leaf_count * kl_div
        p_value = chi2.sf(chi2_statistic, df=total_number_of_features)
        raw_p_values.append(p_value)

    # --- Apply multiple testing correction (e.g., Benjamini-Hochberg) ---
    if not raw_p_values:
        nodes_statistics_dataframe["Are_Features_Dependent"] = False
        return nodes_statistics_dataframe

    rejected, pvals_corrected = apply_multiple_testing_correction(
        raw_p_values, alpha=significance_level_alpha, method=correction_method
    )

    # --- Map corrected results back to the nodes ---
    testable_nodes["P_Value_Raw"] = raw_p_values
    testable_nodes["P_Value_BH_Corrected"] = pvals_corrected
    testable_nodes["Are_Features_Dependent"] = rejected

    # --- Combine results with the original dataframe ---
    cols_to_join = ["P_Value_Raw", "P_Value_BH_Corrected", "Are_Features_Dependent"]
    combined_df = nodes_statistics_dataframe.join(testable_nodes[cols_to_join])

    # Final cleanup on the main significance column
    if "Are_Features_Dependent" in combined_df.columns:
        combined_df["Are_Features_Dependent"] = combined_df[
            "Are_Features_Dependent"
        ].fillna(False).astype(bool)

    return combined_df


def test_feature_independence_conservative(
    kl_divergence_from_uniform: float,
    number_of_leaves_in_node: int,
    number_of_features: int,
    significance_level_alpha: float = 0.05,
    number_of_tests_for_correction: Optional[int] = None,
) -> Dict[str, Union[float, bool, str]]:
    """
    Test if features are independent (CONSERVATIVE with Bonferroni correction).

    This is the MOST CONSERVATIVE test - it corrects for multiple testing by dividing
    alpha by the number of tests (Bonferroni correction). Use this to find only the
    STRONGEST evidence of feature dependence.

    What This Tells You About The Node:
    - "Features Dependent" = Features are associated - node has meaningful structure
    - "Features Independent" = Features are random - node lacks clear structure

    Null Hypothesis (H0): Features are independent (randomly distributed, no associations)
    Alternative Hypothesis (H1): Features are dependent (show associations/structure)

    Test Statistic:
        chi2_statistic = 2 * n_leaves * KL(P || Uniform)
        where n_leaves = number of leaves in this node, P = observed distribution

    Under H0, this statistic follows a chi-squared distribution with df = number_of_features.

    Args:
        kl_divergence_from_uniform: KL divergence D_KL(P || Uniform) for this node
        number_of_leaves_in_node: Number of leaf samples in this node/cluster
        number_of_features: Number of features (degrees of freedom)
        significance_level_alpha: Significance level before correction (default: 0.05)
        number_of_tests_for_correction: Number of tests 'm' for Bonferroni correction.
                                        If None, no correction is applied.

    Returns:
        Dictionary containing (all keys prefixed with 'independence_conservative_'):
        - 'independence_conservative_chi2_statistic': Chi-squared test statistic
        - 'independence_conservative_degrees_of_freedom': Degrees of freedom
        - 'independence_conservative_p_value': P-value from chi-squared test
        - 'independence_conservative_alpha_used': Actual significance level used (after correction)
        - 'independence_conservative_are_features_dependent': Boolean - True if features are dependent
        - 'independence_conservative_result': "Features Dependent" or "Features Independent"

    Example:
        >>> result = test_feature_independence_conservative(
        ...     kl_divergence_from_uniform=0.45,
        ...     number_of_leaves_in_node=100,
        ...     number_of_features=10,
        ...     significance_level_alpha=0.05,
        ...     number_of_tests_for_correction=200
        ... )
        >>> print(result['independence_conservative_are_features_dependent'])
        True
    """
    # Calculate chi-squared statistic
    chi2_statistic = 2 * number_of_leaves_in_node * kl_divergence_from_uniform

    # Degrees of freedom
    degrees_of_freedom = number_of_features

    # Calculate p-value (survival function = 1 - CDF)
    p_value = chi2.sf(chi2_statistic, df=degrees_of_freedom)

    # Apply Bonferroni correction if requested
    if (
        number_of_tests_for_correction is not None
        and number_of_tests_for_correction > 0
    ):
        alpha_used = significance_level_alpha / number_of_tests_for_correction
        correction_note = f"Bonferroni-corrected ({significance_level_alpha}/{number_of_tests_for_correction})"
    else:
        alpha_used = significance_level_alpha
        correction_note = "No correction"

    # Determine if features are dependent
    are_features_dependent = p_value < alpha_used

    # Interpretation
    if are_features_dependent:
        interpretation = (
            "Features are DEPENDENT (associated). "
            "The node shows statistically significant feature structure."
        )
    else:
        interpretation = (
            "Features are INDEPENDENT (random). "
            "The node does NOT show significant structure (at conservative threshold)."
        )

    return {
        "test_name": "Feature Independence Test (Conservative with Bonferroni)",
        "null_hypothesis": "Features are independent (random, no associations)",
        "independence_conservative_chi2_statistic": chi2_statistic,
        "independence_conservative_degrees_of_freedom": degrees_of_freedom,
        "independence_conservative_p_value": p_value,
        "independence_conservative_alpha_used": alpha_used,
        "independence_conservative_alpha_correction": correction_note,
        "independence_conservative_are_features_dependent": are_features_dependent,
        "independence_conservative_result": "Features Dependent"
        if are_features_dependent
        else "Features Independent",
        "independence_conservative_interpretation": interpretation,
    }


def test_feature_independence_liberal(
    kl_divergence_from_uniform: float,
    number_of_leaves_in_node: int,
    number_of_features: int,
    significance_level_alpha: float = 0.05,
) -> Dict[str, Union[float, str, bool]]:
    """
    Test if features are independent (LIBERAL without Bonferroni correction).

    This is LESS CONSERVATIVE than the Bonferroni test - it uses the standard alpha
    without correction, making it more sensitive to detecting patterns.

    What This Tells You About The Node:
    - "Has Pattern" = Features are DEPENDENT (associated) - node likely has structure
    - "No Pattern" = Features are INDEPENDENT (random) - node likely lacks structure

    Null Hypothesis (H0): Features are independent (no associations)
    Alternative Hypothesis (H1): Features are dependent (have associations)

    Test Statistic:
        chi2_statistic = 2 * n_leaves * KL(P || Uniform)

    Under H0, this follows a chi-squared distribution with df = number_of_features.

    Args:
        kl_divergence_from_uniform: KL divergence D_KL(P || Uniform) for this node
        number_of_leaves_in_node: Number of leaf samples in this node/cluster
        number_of_features: Number of features (degrees of freedom)
        significance_level_alpha: Significance level (default: 0.05)

    Returns:
        Dictionary containing (all keys prefixed with 'pattern_liberal_'):
        - 'pattern_liberal_kl_divergence': Input KL divergence value
        - 'pattern_liberal_chi2_statistic': Chi-squared test statistic
        - 'pattern_liberal_degrees_of_freedom': Degrees of freedom
        - 'pattern_liberal_p_value': P-value from test
        - 'pattern_liberal_alpha_used': Significance level used
        - 'pattern_liberal_has_pattern': Boolean - True if features are dependent (has pattern)
        - 'pattern_liberal_result': "Has Pattern" or "No Pattern"

    Example:
        >>> result = test_for_non_uniformity_without_correction(
        ...     kl_divergence_from_uniform=0.02,
        ...     number_of_leaves_in_node=100,
        ...     number_of_features=10,
        ...     significance_level_alpha=0.05
        ... )
        >>> print(result['pattern_liberal_result'])
        'No Pattern'
    """
    # Calculate chi-squared statistic
    chi2_statistic = 2 * number_of_leaves_in_node * kl_divergence_from_uniform

    # Degrees of freedom
    degrees_of_freedom = number_of_features

    # Calculate p-value (survival function = 1 - CDF)
    p_value = chi2.sf(chi2_statistic, df=degrees_of_freedom)

    # Determine if features are dependent
    are_features_dependent = p_value < significance_level_alpha  # Reject H0 → Dependent

    # Result
    result = "Features Dependent" if are_features_dependent else "Features Independent"

    # Interpretation
    if are_features_dependent:
        interpretation = (
            f"p-value ({p_value:.4f}) < alpha ({significance_level_alpha}). "
            f"Reject null hypothesis of independence. "
            f"Features are DEPENDENT (KL={kl_divergence_from_uniform:.4f}), "
            "indicating the node has meaningful feature associations."
        )
    else:
        interpretation = (
            f"p-value ({p_value:.4f}) ≥ alpha ({significance_level_alpha}). "
            f"Fail to reject null hypothesis of independence. "
            f"Features are INDEPENDENT (KL={kl_divergence_from_uniform:.4f}), "
            "suggesting random feature distribution."
        )

    return {
        "test_name": "Feature Independence Test (Liberal, No Bonferroni)",
        "null_hypothesis": "Features are independent (no associations)",
        "independence_liberal_kl_divergence": kl_divergence_from_uniform,
        "independence_liberal_chi2_statistic": chi2_statistic,
        "independence_liberal_degrees_of_freedom": degrees_of_freedom,
        "independence_liberal_p_value": p_value,
        "independence_liberal_alpha_used": significance_level_alpha,
        "independence_liberal_are_features_dependent": are_features_dependent,
        "independence_liberal_result": result,
        "independence_liberal_interpretation": interpretation,
    }


def kl_divergence_deviation_from_zero_test(
    kl_divergence: float,
    all_kl_divergences: np.ndarray,
    alpha: float = 0.05,
    num_std: float = 2.0,
) -> Dict[str, Union[float, bool, str]]:
    """
    Test if KL divergence is significantly different from zero.

    This test measures how many standard deviations away from zero a node's KL divergence is,
    using the empirical standard deviation of internal nodes as the measurement scale.

    Null Hypothesis (H0): The node's KL divergence equals zero (perfect uniformity).
    Alternative Hypothesis (H1): The node's KL divergence is significantly greater than zero.

    The test calculates:
    - z_score = kl_divergence / std_kl (deviation from zero in units of std)
    - Critical value based on alpha (e.g., alpha=0.05 → z_crit ≈ 1.96 for two-tailed)
    - is_significant = |z_score| > z_critical

    NOTE: all_kl_divergences should contain only INTERNAL nodes to avoid zero std_dev
    when all leaves have identical KL divergence.

    Args:
        kl_divergence: KL divergence for the node being tested
        all_kl_divergences: Array of KL divergences from INTERNAL nodes only
        alpha: Significance level (default: 0.05)
        num_std: Number of standard deviations for threshold (default: 2.0)

    Returns:
        Dictionary containing:
        - 'test_name': Name of the test
        - 'kl_divergence': Input KL divergence value
        - 'std_kl': Standard deviation of internal nodes' KL divergences
        - 'num_std_used': Number of standard deviations used
        - 'threshold': Threshold value (num_std * std_kl)
        - 'z_score': Standardized score = kl_divergence / std_kl
        - 'is_significant': Boolean indicating if |z_score| exceeds threshold
        - 'result': Human-readable result string
        - 'interpretation': What the result means

    Example:
        >>> internal_kls = np.array([0.01, 0.02, 0.015, 0.45, 0.03, 0.02])
        >>> result = kl_divergence_deviation_from_zero_test(
        ...     kl_divergence=0.45,
        ...     all_kl_divergences=internal_kls,
        ...     alpha=0.05
        ... )
        >>> print(result['is_significant'])
        True
    """
    # Calculate standard deviation from internal nodes (baseline is zero, not mean)
    std_kl = np.std(all_kl_divergences) if len(all_kl_divergences) > 0 else 0.0

    # Calculate z-score: how many std devs away from zero?
    if std_kl > 0:
        z_score = kl_divergence / std_kl  # Deviation from zero
    else:
        z_score = 0.0

    # Calculate threshold (in KL divergence units)
    threshold = num_std * std_kl

    # Determine significance (two-tailed test: could be above or below zero)
    is_significant = abs(z_score) > num_std

    # Interpretation
    if is_significant:
        interpretation = (
            f"KL divergence ({kl_divergence:.4f}) is {abs(z_score):.2f}σ away from zero, "
            f"exceeding the {num_std}σ threshold ({threshold:.4f}). "
            "Node shows significant deviation from perfect uniformity, "
            "indicating structured, non-random feature patterns."
        )
    else:
        interpretation = (
            f"KL divergence ({kl_divergence:.4f}) is {abs(z_score):.2f}σ from zero, "
            f"within the {num_std}σ threshold ({threshold:.4f}). "
            "Node does not significantly deviate from uniformity, "
            "consistent with independence or random variation."
        )

    return {
        "test_name": f"KL Divergence Deviation from Zero Test ({num_std}σ)",
        "null_hypothesis": "KL divergence equals zero (perfect uniformity)",
        "kl_divergence": kl_divergence,
        "std_kl": std_kl,
        "num_std_used": num_std,
        "threshold": threshold,
        "z_score": z_score,
        "alpha": alpha,
        "is_significant": is_significant,
        "result": "Significant" if is_significant else "Not Significant",
        "interpretation": interpretation,
    }


def apply_benjamini_hochberg_correction(
    p_values: list, significance_level_alpha: float = 0.05
) -> Dict[str, Union[list, bool, float]]:
    """
    Apply the Benjamini-Hochberg procedure to control the False Discovery Rate (FDR).

    Args:
        p_values (list): A list of p-values from the hypothesis tests.
        significance_level_alpha (float): The desired FDR control level.

    Returns:
        A dictionary containing the boolean array of rejected hypotheses and corrected p-values.
    """
    if not p_values:
        return {
            "significant": [],
            "p_values_corrected": [],
        }

    significant, p_values_corrected, _, _ = multipletests(
        p_values, alpha=significance_level_alpha, method="fdr_bh"
    )
    return {
        "significant": significant,
        "p_values_corrected": p_values_corrected,
    }


def perform_all_significance_tests_for_single_node(
    node_kl_divergence_from_uniform: float,
    node_number_of_leaves: int,
    total_number_of_features: int,
    significance_level_alpha: float = 0.05,
    number_of_tests_for_bonferroni: Optional[int] = None,
    all_nodes_kl_divergences: Optional[np.ndarray] = None,
    std_deviation_threshold: float = 2.0,
) -> Dict[str, Union[Dict, bool, str]]:
    """
    Perform all available significance tests on a single node for informational purposes.

    The main significance decision should be made later using a multiple testing correction
    like Benjamini-Hochberg across all nodes.

    Args:
        node_kl_divergence_from_uniform: KL divergence for this node.
        node_number_of_leaves: Number of leaves in this node.
        total_number_of_features: Total features in the dataset.
        significance_level_alpha: Significance level for all tests.
        number_of_tests_for_bonferroni: Number of tests for Bonferroni correction.
        all_nodes_kl_divergences: Array of KL divergences for deviation test.
        std_deviation_threshold: Number of std deviations for deviation test.

    Returns:
        Dictionary containing results from conservative, liberal, and deviation tests,
        plus a combined informational 'is_significant_overall' flag.
    """
    # Test 1: Feature independence with Bonferroni correction
    independence_conservative_results = test_feature_independence_conservative(
        kl_divergence_from_uniform=node_kl_divergence_from_uniform,
        number_of_leaves_in_node=node_number_of_leaves,
        number_of_features=total_number_of_features,
        significance_level_alpha=significance_level_alpha,
        number_of_tests_for_correction=number_of_tests_for_bonferroni,
    )

    # Test 2: Feature independence without correction (liberal)
    independence_liberal_results = test_feature_independence_liberal(
        kl_divergence_from_uniform=node_kl_divergence_from_uniform,
        number_of_leaves_in_node=node_number_of_leaves,
        number_of_features=total_number_of_features,
        significance_level_alpha=significance_level_alpha,
    )

    # Test 3: Deviation from baseline test (optional, empirical)
    deviation_results = None
    if all_nodes_kl_divergences is not None and len(all_nodes_kl_divergences) > 1:
        deviation_results = kl_divergence_deviation_from_zero_test(
            kl_divergence=node_kl_divergence_from_uniform,
            all_kl_divergences=all_nodes_kl_divergences,
            alpha=significance_level_alpha,
            num_std=std_deviation_threshold,
        )

    # Combined informational significance: TRUE if ANY test shows feature dependence
    is_significant_overall = (
        independence_conservative_results[
            "independence_conservative_are_features_dependent"
        ]
        or independence_liberal_results["independence_liberal_are_features_dependent"]
    )
    if deviation_results is not None:
        is_significant_overall = (
            is_significant_overall or deviation_results["is_significant"]
        )

    # Create summary
    summary_parts = [
        f"Independence (Conservative/Bonferroni): {independence_conservative_results['independence_conservative_result']} (p={independence_conservative_results['independence_conservative_p_value']:.4f})",
        f"Independence (Liberal/No correction): {independence_liberal_results['independence_liberal_result']} (p={independence_liberal_results['independence_liberal_p_value']:.4f})",
    ]
    if deviation_results is not None:
        summary_parts.append(
            f"Deviation ({std_deviation_threshold}σ): {deviation_results['result']} (z={deviation_results['z_score']:.2f})"
        )
    summary_parts.append(
        f"Overall (Informational): {'FEATURES DEPENDENT' if is_significant_overall else 'Features Independent'}"
    )
    tests_summary = "\n".join(summary_parts)

    result = {
        "independence_test_conservative": independence_conservative_results,
        "independence_test_liberal": independence_liberal_results,
        "is_significant_overall_informational": is_significant_overall,
        "tests_summary": tests_summary,
    }

    if deviation_results is not None:
        result["deviation_from_baseline_test"] = deviation_results

    return result


def annotate_nodes_with_statistical_significance_tests(
    nodes_statistics_dataframe: pd.DataFrame,
    total_number_of_features: int,
    significance_level_alpha: float = 0.05,
    correction_method: str = "fdr_bh",  # fdr_bh is Benjamini-Hochberg
    std_deviation_threshold: float = 2.0,
    include_deviation_test: bool = False,
) -> pd.DataFrame:
    """
    Perform significance tests on all nodes and apply multiple testing correction.

    This function uses the Benjamini-Hochberg procedure to control the False Discovery Rate
    and determine the final 'Are_Features_Dependent' column, which should be used for
    downstream decomposition.

    Args:
        nodes_statistics_dataframe: DataFrame with REQUIRED columns:
            - 'kl_divergence_local': KL divergence value for each node vs. its parent.
            - 'leaf_count': Number of leaves (samples) in each node.
        total_number_of_features: Total number of features in the dataset.
        significance_level_alpha: Significance level (FDR rate) for correction.
        correction_method: Method for multiple testing correction (e.g., 'fdr_bh').
        std_deviation_threshold: For the informational deviation test.
        include_deviation_test: Whether to include the informational deviation test.

    Returns:
        An annotated DataFrame with results from all tests. The key column for
        decomposition is 'Are_Features_Dependent', determined by Benjamini-Hochberg.
    """
    p_values_data = {}

    # --- Pass 1: Gather all raw p-values ---
    for node_id, row in nodes_statistics_dataframe.iterrows():
        kl_div = row.get("kl_divergence_local")
        leaf_count = row.get("leaf_count")

        # Test is only applicable for nodes with a local KL divergence value
        if kl_div is None or pd.isna(kl_div) or not leaf_count:
            continue

        # Calculate the chi-squared statistic and raw p-value
        chi2_statistic = 2 * leaf_count * kl_div
        p_value = chi2.sf(chi2_statistic, df=total_number_of_features)
        p_values_data[node_id] = p_value

    # --- Apply multiple testing correction (e.g., Benjamini-Hochberg) ---
    if not p_values_data:
        # No nodes were testable, return the original dataframe
        nodes_statistics_dataframe["Are_Features_Dependent"] = False
        return nodes_statistics_dataframe

    node_ids = list(p_values_data.keys())
    p_values_list = list(p_values_data.values())

    significant_results, p_values_corrected, _, _ = multipletests(
        p_values_list, alpha=significance_level_alpha, method=correction_method
    )

    # Map the significance results back to the node IDs
    bh_significance_map = dict(zip(node_ids, significant_results))

    # --- Pass 2: Generate full informational results for all tests ---
    results = []
    processed_indices = []

    # For deviation test, get all local KL divergences from internal nodes
    all_nodes_kl_divergences = None
    if include_deviation_test:
        kl_column = "kl_divergence_local"
        if "is_leaf" in nodes_statistics_dataframe.columns:
            internal_nodes = nodes_statistics_dataframe[
                ~nodes_statistics_dataframe["is_leaf"]
            ]
            all_nodes_kl_divergences = internal_nodes[kl_column].dropna().values
        else:
            all_nodes_kl_divergences = (
                nodes_statistics_dataframe[kl_column].dropna().values
            )

    for idx, row in nodes_statistics_dataframe.iterrows():
        kl_div = row.get("kl_divergence_local")
        leaf_count = row.get("leaf_count")

        # Prepare inputs for the informational tests
        bonferroni_m = len(p_values_data)
        test_results = perform_all_significance_tests_for_single_node(
            node_kl_divergence_from_uniform=kl_div
            if kl_div is not None and not pd.isna(kl_div)
            else 0,
            node_number_of_leaves=leaf_count if leaf_count is not None else 0,
            total_number_of_features=total_number_of_features,
            significance_level_alpha=significance_level_alpha,
            number_of_tests_for_bonferroni=bonferroni_m,
            all_nodes_kl_divergences=all_nodes_kl_divergences
            if include_deviation_test
            else None,
            std_deviation_threshold=std_deviation_threshold,
        )

        # Build the result row
        conservative_res = test_results["independence_test_conservative"]
        liberal_res = test_results["independence_test_liberal"]
        result_row = {
            "Independence_Conservative_P_Value": conservative_res[
                "independence_conservative_p_value"
            ],
            "Independence_Conservative_Result": conservative_res[
                "independence_conservative_result"
            ],
            "Independence_Liberal_P_Value": liberal_res["independence_liberal_p_value"],
            "Independence_Liberal_Result": liberal_res["independence_liberal_result"],
            "P_Value_BH_Corrected": p_values_corrected[node_ids.index(idx)]
            if idx in node_ids
            else np.nan,
            "Are_Features_Dependent": bh_significance_map.get(
                idx, False
            ),  # Main result from BH
        }

        if include_deviation_test and test_results.get("deviation_from_baseline_test"):
            dev_test = test_results["deviation_from_baseline_test"]
            result_row["Deviation_Z_Score"] = dev_test["z_score"]
            result_row["Deviation_Result"] = dev_test["result"]

        results.append(result_row)
        processed_indices.append(idx)

    # Create DataFrame with results
    results_df = pd.DataFrame(results, index=processed_indices)

    # Combine with original DataFrame
    combined_df = pd.concat([nodes_statistics_dataframe, results_df], axis=1)

    # Final cleanup on the main significance column
    if "Are_Features_Dependent" in combined_df.columns:
        combined_df["Are_Features_Dependent"] = combined_df[
            "Are_Features_Dependent"
        ].fillna(False)

    return combined_df


def test_feature_independence_conservative(
    kl_divergence_from_uniform: float,
    number_of_leaves_in_node: int,
    number_of_features: int,
    significance_level_alpha: float = 0.05,
    number_of_tests_for_correction: Optional[int] = None,
) -> Dict[str, Union[float, bool, str]]:
    """
    Test if features are independent (CONSERVATIVE with Bonferroni correction).

    This is the MOST CONSERVATIVE test - it corrects for multiple testing by dividing
    alpha by the number of tests (Bonferroni correction). Use this to find only the
    STRONGEST evidence of feature dependence.

    What This Tells You About The Node:
    - "Features Dependent" = Features are associated - node has meaningful structure
    - "Features Independent" = Features are random - node lacks clear structure

    Null Hypothesis (H0): Features are independent (randomly distributed, no associations)
    Alternative Hypothesis (H1): Features are dependent (show associations/structure)

    Test Statistic:
        chi2_statistic = 2 * n_leaves * KL(P || Uniform)
        where n_leaves = number of leaves in this node, P = observed distribution

    Under H0, this statistic follows a chi-squared distribution with df = number_of_features.

    Args:
        kl_divergence_from_uniform: KL divergence D_KL(P || Uniform) for this node
        number_of_leaves_in_node: Number of leaf samples in this node/cluster
        number_of_features: Number of features (degrees of freedom)
        significance_level_alpha: Significance level before correction (default: 0.05)
        number_of_tests_for_correction: Number of tests 'm' for Bonferroni correction.
                                        If None, no correction is applied.

    Returns:
        Dictionary containing (all keys prefixed with 'independence_conservative_'):
        - 'independence_conservative_chi2_statistic': Chi-squared test statistic
        - 'independence_conservative_degrees_of_freedom': Degrees of freedom
        - 'independence_conservative_p_value': P-value from chi-squared test
        - 'independence_conservative_alpha_used': Actual significance level used (after correction)
        - 'independence_conservative_are_features_dependent': Boolean - True if features are dependent
        - 'independence_conservative_result': "Features Dependent" or "Features Independent"

    Example:
        >>> result = test_feature_independence_conservative(
        ...     kl_divergence_from_uniform=0.45,
        ...     number_of_leaves_in_node=100,
        ...     number_of_features=10,
        ...     significance_level_alpha=0.05,
        ...     number_of_tests_for_correction=200
        ... )
        >>> print(result['independence_conservative_are_features_dependent'])
        True
    """
    # Calculate chi-squared statistic
    chi2_statistic = 2 * number_of_leaves_in_node * kl_divergence_from_uniform

    # Degrees of freedom
    degrees_of_freedom = number_of_features

    # Calculate p-value (survival function = 1 - CDF)
    p_value = chi2.sf(chi2_statistic, df=degrees_of_freedom)

    # Apply Bonferroni correction if requested
    if (
        number_of_tests_for_correction is not None
        and number_of_tests_for_correction > 0
    ):
        alpha_used = significance_level_alpha / number_of_tests_for_correction
        correction_note = f"Bonferroni-corrected ({significance_level_alpha}/{number_of_tests_for_correction})"
    else:
        alpha_used = significance_level_alpha
        correction_note = "No correction"

    # Determine if features are dependent
    are_features_dependent = p_value < alpha_used

    # Interpretation
    if are_features_dependent:
        interpretation = (
            "Features are DEPENDENT (associated). "
            "The node shows statistically significant feature structure."
        )
    else:
        interpretation = (
            "Features are INDEPENDENT (random). "
            "The node does NOT show significant structure (at conservative threshold)."
        )

    return {
        "test_name": "Feature Independence Test (Conservative with Bonferroni)",
        "null_hypothesis": "Features are independent (random, no associations)",
        "independence_conservative_chi2_statistic": chi2_statistic,
        "independence_conservative_degrees_of_freedom": degrees_of_freedom,
        "independence_conservative_p_value": p_value,
        "independence_conservative_alpha_used": alpha_used,
        "independence_conservative_alpha_correction": correction_note,
        "independence_conservative_are_features_dependent": are_features_dependent,
        "independence_conservative_result": "Features Dependent"
        if are_features_dependent
        else "Features Independent",
        "independence_conservative_interpretation": interpretation,
    }


def test_feature_independence_liberal(
    kl_divergence_from_uniform: float,
    number_of_leaves_in_node: int,
    number_of_features: int,
    significance_level_alpha: float = 0.05,
) -> Dict[str, Union[float, str, bool]]:
    """
    Test if features are independent (LIBERAL without Bonferroni correction).

    This is LESS CONSERVATIVE than the Bonferroni test - it uses the standard alpha
    This is LESS CONSERVATIVE than the Bonferroni test - it uses the standard alpha
    without correction, making it more sensitive to detecting patterns.

    What This Tells You About The Node:
    - "Has Pattern" = Features are DEPENDENT (associated) - node likely has structure
    - "No Pattern" = Features are INDEPENDENT (random) - node likely lacks structure

    Null Hypothesis (H0): Features are independent (no associations)
    Alternative Hypothesis (H1): Features are dependent (have associations)

    Test Statistic:
        chi2_statistic = 2 * n_leaves * KL(P || Uniform)

    Under H0, this follows a chi-squared distribution with df = number_of_features.

    Args:
        kl_divergence_from_uniform: KL divergence D_KL(P || Uniform) for this node
        number_of_leaves_in_node: Number of leaf samples in this node/cluster
        number_of_features: Number of features (degrees of freedom)
        significance_level_alpha: Significance level (default: 0.05)

    Returns:
        Dictionary containing (all keys prefixed with 'pattern_liberal_'):
        - 'pattern_liberal_kl_divergence': Input KL divergence value
        - 'pattern_liberal_chi2_statistic': Chi-squared test statistic
        - 'pattern_liberal_degrees_of_freedom': Degrees of freedom
        - 'pattern_liberal_p_value': P-value from test
        - 'pattern_liberal_alpha_used': Significance level used
        - 'pattern_liberal_has_pattern': Boolean - True if features are dependent (has pattern)
        - 'pattern_liberal_result': "Has Pattern" or "No Pattern"

    Example:
        >>> result = test_for_non_uniformity_without_correction(
        ...     kl_divergence_from_uniform=0.02,
        ...     number_of_leaves_in_node=100,
        ...     number_of_features=10,
        ...     significance_level_alpha=0.05
        ... )
        >>> print(result['pattern_liberal_result'])
        'No Pattern'
    """
    # Calculate chi-squared statistic
    chi2_statistic = 2 * number_of_leaves_in_node * kl_divergence_from_uniform

    # Degrees of freedom
    degrees_of_freedom = number_of_features

    # Calculate p-value (survival function = 1 - CDF)
    p_value = chi2.sf(chi2_statistic, df=degrees_of_freedom)

    # Determine if features are dependent
    are_features_dependent = p_value < significance_level_alpha  # Reject H0 → Dependent

    # Result
    result = "Features Dependent" if are_features_dependent else "Features Independent"

    # Interpretation
    if are_features_dependent:
        interpretation = (
            f"p-value ({p_value:.4f}) < alpha ({significance_level_alpha}). "
            f"Reject null hypothesis of independence. "
            f"Features are DEPENDENT (KL={kl_divergence_from_uniform:.4f}), "
            "indicating the node has meaningful feature associations."
        )
    else:
        interpretation = (
            f"p-value ({p_value:.4f}) ≥ alpha ({significance_level_alpha}). "
            f"Fail to reject null hypothesis of independence. "
            f"Features are INDEPENDENT (KL={kl_divergence_from_uniform:.4f}), "
            "suggesting random feature distribution."
        )

    return {
        "test_name": "Feature Independence Test (Liberal, No Bonferroni)",
        "null_hypothesis": "Features are independent (no associations)",
        "independence_liberal_kl_divergence": kl_divergence_from_uniform,
        "independence_liberal_chi2_statistic": chi2_statistic,
        "independence_liberal_degrees_of_freedom": degrees_of_freedom,
        "independence_liberal_p_value": p_value,
        "independence_liberal_alpha_used": significance_level_alpha,
        "independence_liberal_are_features_dependent": are_features_dependent,
        "independence_liberal_result": result,
        "independence_liberal_interpretation": interpretation,
    }


def kl_divergence_deviation_from_zero_test(
    kl_divergence: float,
    all_kl_divergences: np.ndarray,
    alpha: float = 0.05,
    num_std: float = 2.0,
) -> Dict[str, Union[float, bool, str]]:
    """
    Test if KL divergence is significantly different from zero.

    This test measures how many standard deviations away from zero a node's KL divergence is,
    using the empirical standard deviation of internal nodes as the measurement scale.

    Null Hypothesis (H0): The node's KL divergence equals zero (perfect uniformity).
    Alternative Hypothesis (H1): The node's KL divergence is significantly greater than zero.

    The test calculates:
    - z_score = kl_divergence / std_kl (deviation from zero in units of std)
    - Critical value based on alpha (e.g., alpha=0.05 → z_crit ≈ 1.96 for two-tailed)
    - is_significant = |z_score| > z_critical

    NOTE: all_kl_divergences should contain only INTERNAL nodes to avoid zero std_dev
    when all leaves have identical KL divergence.

    Args:
        kl_divergence: KL divergence for the node being tested
        all_kl_divergences: Array of KL divergences from INTERNAL nodes only
        alpha: Significance level (default: 0.05)
        num_std: Number of standard deviations for threshold (default: 2.0)

    Returns:
        Dictionary containing:
        - 'test_name': Name of the test
        - 'kl_divergence': Input KL divergence value
        - 'std_kl': Standard deviation of internal nodes' KL divergences
        - 'num_std_used': Number of standard deviations used
        - 'threshold': Threshold value (num_std * std_kl)
        - 'z_score': Standardized score = kl_divergence / std_kl
        - 'is_significant': Boolean indicating if |z_score| exceeds threshold
        - 'result': Human-readable result string
        - 'interpretation': What the result means

    Example:
        >>> internal_kls = np.array([0.01, 0.02, 0.015, 0.45, 0.03, 0.02])
        >>> result = kl_divergence_deviation_from_zero_test(
        ...     kl_divergence=0.45,
        ...     all_kl_divergences=internal_kls,
        ...     alpha=0.05
        ... )
        >>> print(result['is_significant'])
        True
    """
    # Calculate standard deviation from internal nodes (baseline is zero, not mean)
    std_kl = np.std(all_kl_divergences) if len(all_kl_divergences) > 0 else 0.0

    # Calculate z-score: how many std devs away from zero?
    if std_kl > 0:
        z_score = kl_divergence / std_kl  # Deviation from zero
    else:
        z_score = 0.0

    # Calculate threshold (in KL divergence units)
    threshold = num_std * std_kl

    # Determine significance (two-tailed test: could be above or below zero)
    is_significant = abs(z_score) > num_std

    # Interpretation
    if is_significant:
        interpretation = (
            f"KL divergence ({kl_divergence:.4f}) is {abs(z_score):.2f}σ away from zero, "
            f"exceeding the {num_std}σ threshold ({threshold:.4f}). "
            "Node shows significant deviation from perfect uniformity, "
            "indicating structured, non-random feature patterns."
        )
    else:
        interpretation = (
            f"KL divergence ({kl_divergence:.4f}) is {abs(z_score):.2f}σ from zero, "
            f"within the {num_std}σ threshold ({threshold:.4f}). "
            "Node does not significantly deviate from uniformity, "
            "consistent with independence or random variation."
        )

    return {
        "test_name": f"KL Divergence Deviation from Zero Test ({num_std}σ)",
        "null_hypothesis": "KL divergence equals zero (perfect uniformity)",
        "kl_divergence": kl_divergence,
        "std_kl": std_kl,
        "num_std_used": num_std,
        "threshold": threshold,
        "z_score": z_score,
        "alpha": alpha,
        "is_significant": is_significant,
        "result": "Significant" if is_significant else "Not Significant",
        "interpretation": interpretation,
    }


def perform_all_significance_tests_for_single_node(
    node_kl_divergence_from_uniform: float,
    node_number_of_leaves: int,
    total_number_of_features: int,
    all_nodes_kl_divergences: Optional[np.ndarray] = None,
    significance_level_alpha: float = 0.05,
    number_of_tests_for_correction: Optional[int] = None,
    std_deviation_threshold: float = 2.0,
) -> Dict[str, Union[Dict, bool, str]]:
    """
    Perform all available significance tests on a single node.

    Combines up to three tests to provide comprehensive statistical assessment:
    1. Feature independence test with Bonferroni correction (most conservative)
    2. Feature independence test without correction (less conservative)
    3. Deviation from baseline test (optional, empirical outlier detection)

    Args:
        node_kl_divergence_from_uniform: KL divergence for this node
        node_number_of_leaves: Number of leaves (samples) in this node
        total_number_of_features: Total number of features in the dataset
        all_nodes_kl_divergences: Array of KL divergences from ALL nodes (for deviation test).
                                  If None, deviation test is skipped.
        significance_level_alpha: Significance level for all tests (default: 0.05)
        number_of_tests_for_correction: Number of tests 'm' for Bonferroni correction.
        std_deviation_threshold: Number of standard deviations for deviation test (default: 2.0)

    Returns:
        Dictionary containing:
        - 'independence_test_conservative': Full results from independence test with Bonferroni
        - 'independence_test_liberal': Full results from independence test without Bonferroni
        - 'deviation_from_baseline_test': Full results from deviation test (if all_nodes_kl_divergences provided)
        - 'is_significant_overall': Significance based on the conservative test.
        - 'tests_summary': Human-readable summary of all tests

    Example:
        >>> all_kls = np.array([0.01, 0.02, 0.015, 0.45, 0.03, 0.02])
        >>> results = perform_all_significance_tests_for_single_node(
        ...     node_kl_divergence_from_uniform=0.45,
        ...     node_number_of_leaves=100,
        ...     total_number_of_features=10,
        ...     all_nodes_kl_divergences=all_kls,
        ...     number_of_tests_for_correction=200
        ... )
        >>> print(results['tests_summary'])
    """
    # Test 1: Feature independence with Bonferroni correction (most conservative)
    independence_conservative_results = test_feature_independence_conservative(
        kl_divergence_from_uniform=node_kl_divergence_from_uniform,
        number_of_leaves_in_node=node_number_of_leaves,
        number_of_features=total_number_of_features,
        significance_level_alpha=significance_level_alpha,
        number_of_tests_for_correction=number_of_tests_for_correction,
    )

    # Test 2: Feature independence without Bonferroni (less conservative / more liberal)
    independence_liberal_results = test_feature_independence_liberal(
        kl_divergence_from_uniform=node_kl_divergence_from_uniform,
        number_of_leaves_in_node=node_number_of_leaves,
        number_of_features=total_number_of_features,
        significance_level_alpha=significance_level_alpha,
    )

    # Test 3: Deviation from baseline test (optional, empirical)
    deviation_results = None
    if all_nodes_kl_divergences is not None:
        deviation_results = kl_divergence_deviation_from_zero_test(
            kl_divergence=node_kl_divergence_from_uniform,
            all_kl_divergences=all_nodes_kl_divergences,
            alpha=significance_level_alpha,
            num_std=std_deviation_threshold,
        )

    # Significance is now based ONLY on the corrected conservative test
    is_significant_overall = independence_conservative_results[
        "independence_conservative_are_features_dependent"
    ]

    # Create summary
    summary_parts = [
        f"Independence (Conservative/Bonferroni): {independence_conservative_results['independence_conservative_result']} (p={independence_conservative_results['independence_conservative_p_value']:.4f})",
        f"Independence (Liberal/No correction): {independence_liberal_results['independence_liberal_result']} (p={independence_liberal_results['independence_liberal_p_value']:.4f})",
    ]
    if deviation_results is not None:
        summary_parts.append(
            f"Deviation ({std_deviation_threshold}σ): {deviation_results['result']} (z={deviation_results['z_score']:.2f})"
        )
    summary_parts.append(
        f"Overall: {'FEATURES DEPENDENT' if is_significant_overall else 'Features Independent'} (based on Conservative test)"
    )
    tests_summary = "\n".join(summary_parts)

    result = {
        "independence_test_conservative": independence_conservative_results,
        "independence_test_liberal": independence_liberal_results,
        "is_significant_overall": is_significant_overall,
        "tests_summary": tests_summary,
    }

    if deviation_results is not None:
        result["deviation_from_baseline_test"] = deviation_results

    return result


def annotate_nodes_with_statistical_significance_tests(
    nodes_statistics_dataframe: pd.DataFrame,
    total_number_of_features: int,
    significance_level_alpha: float = 0.05,
    apply_bonferroni_correction: bool = True,
    std_deviation_threshold: float = 2.0,
    include_deviation_test: bool = False,
) -> pd.DataFrame:
    """
    Perform significance tests on all nodes in a DataFrame and return annotated results.

    This function applies statistical tests to each node and returns an enhanced DataFrame
    with test results appended as new columns.

    Args:
        nodes_statistics_dataframe: DataFrame with these REQUIRED columns:
            - 'kl_divergence_local': KL divergence value for each node vs. its parent.
            - 'leaf_count': Number of leaves (samples) in each node.
            - 'distribution': Feature distribution for each node.
            Optional: node identifier as index or 'Node' column.
        total_number_of_features: Total number of features in the dataset
        significance_level_alpha: Significance level for all tests (default: 0.05)
        apply_bonferroni_correction: Apply Bonferroni correction to uniformity test (default: True)
        std_deviation_threshold: Number of standard deviations for deviation test (default: 2.0)
        include_deviation_test: Whether to include deviation from baseline test (default: False)

    Returns:
        DataFrame with original columns PLUS new columns (all prefixed by test name):

        From Independence Test (Conservative with Bonferroni):
        - 'Independence_Conservative_Chi2_Statistic': Chi-squared test statistic
        - 'Independence_Conservative_Degrees_of_Freedom': Degrees of freedom
        - 'Independence_Conservative_P_Value': P-value from test
        - 'Independence_Conservative_Alpha_Used': Significance level used (after correction)
        - 'Independence_Conservative_Result': 'Features Dependent' or 'Features Independent'

        From Independence Test (Liberal, No Correction):
        - 'Independence_Liberal_P_Value': P-value from test
        - 'Independence_Liberal_Result': 'Features Dependent' or 'Features Independent'

        From Deviation Test (if include_deviation_test=True):
        - 'Deviation_Z_Score': Z-score
        - 'Deviation_Threshold': Threshold value
        - 'Deviation_Result': 'Significant' or 'Not Significant'

        Combined:
        - 'Are_Features_Dependent': Boolean - True if the CONSERVATIVE test shows feature dependence.
        - 'Mean_of_Distribution': Mean of the distribution
        - 'Variance_of_Distribution': Variance of the distribution

    Example:
        >>> results_df = annotate_nodes_with_statistical_significance_tests(
            ...     nodes_statistics_dataframe=node_stats_df,
        ...     total_number_of_features=10
        ... )
        >>> dependent_nodes = results_df[results_df['Are_Features_Dependent']]
        >>> print(f"Found {len(dependent_nodes)} nodes with dependent features")
    """
    # Determine the number of tests for Bonferroni correction
    number_of_tests_for_correction = None
    if apply_bonferroni_correction:
        # Find total number of leaves 'n' by finding the max leaf_count, which should be the root.
        if (
            "leaf_count" in nodes_statistics_dataframe.columns
            and not nodes_statistics_dataframe.empty
        ):
            n_total_leaves = nodes_statistics_dataframe["leaf_count"].max()
            if n_total_leaves > 1:
                # User-specified formula for the number of tests 'm'
                number_of_tests_for_correction = 2 * n_total_leaves - 3

        if (
            number_of_tests_for_correction is None
            or number_of_tests_for_correction <= 0
        ):
            # Fallback to number of nodes if formula is not applicable
            number_of_tests_for_correction = len(nodes_statistics_dataframe)

    # Extract KL divergences from INTERNAL NODES ONLY for deviation test baseline
    # (Leaves often have identical/very similar KL divergences, causing std=0)
    all_nodes_kl_divergences = None
    if include_deviation_test:
        # Use the local KL divergence for this test as well
        kl_column_for_deviation = "kl_divergence_local"
        # Filter to only internal nodes (non-leaves)
        if "is_leaf" in nodes_statistics_dataframe.columns:
            internal_only = nodes_statistics_dataframe[
                ~nodes_statistics_dataframe["is_leaf"]
            ]
            all_nodes_kl_divergences = (
                internal_only[kl_column_for_deviation].dropna().values
            )
        else:
            # Fallback: use all nodes if is_leaf column not available
            all_nodes_kl_divergences = (
                nodes_statistics_dataframe[kl_column_for_deviation].dropna().values
            )

    results = []
    processed_indices = []

    for idx, row in nodes_statistics_dataframe.iterrows():
        # Use the LOCAL KL divergence for significance testing
        kl_div = row.get("kl_divergence_local")
        leaf_count = row.get("leaf_count")
        distribution = row.get("distribution")

        # Skip if missing required fields, or if KL is NaN (e.g. for root node)
        if kl_div is None or pd.isna(kl_div) or leaf_count is None:
            continue

        # Perform all tests
        test_results = perform_all_significance_tests_for_single_node(
            node_kl_divergence_from_uniform=kl_div,
            node_number_of_leaves=leaf_count,
            total_number_of_features=total_number_of_features,
            all_nodes_kl_divergences=all_nodes_kl_divergences,
            significance_level_alpha=significance_level_alpha,
            number_of_tests_for_correction=number_of_tests_for_correction,
            std_deviation_threshold=std_deviation_threshold,
        )

        # Extract results from both independence tests
        independence_conservative = test_results["independence_test_conservative"]
        independence_liberal = test_results["independence_test_liberal"]

        result_row = {
            "Independence_Conservative_Chi2_Statistic": independence_conservative[
                "independence_conservative_chi2_statistic"
            ],
            "Independence_Conservative_Degrees_of_Freedom": independence_conservative[
                "independence_conservative_degrees_of_freedom"
            ],
            "Independence_Conservative_P_Value": independence_conservative[
                "independence_conservative_p_value"
            ],
            "Independence_Conservative_Alpha_Used": independence_conservative[
                "independence_conservative_alpha_used"
            ],
            "Independence_Conservative_Result": independence_conservative[
                "independence_conservative_result"
            ],
            "Independence_Liberal_P_Value": independence_liberal[
                "independence_liberal_p_value"
            ],
            "Independence_Liberal_Result": independence_liberal[
                "independence_liberal_result"
            ],
            "Are_Features_Dependent": test_results["is_significant_overall"],
            "Mean_of_Distribution": np.mean(distribution)
            if distribution is not None
            else np.nan,
            "Variance_of_Distribution": np.var(distribution)
            if distribution is not None
            else np.nan,
        }

        # Add deviation test results if included
        if include_deviation_test and "deviation_from_baseline_test" in test_results:
            dev_test = test_results["deviation_from_baseline_test"]
            result_row["Deviation_Z_Score"] = dev_test["z_score"]
            result_row["Deviation_Threshold"] = dev_test["threshold"]
            result_row["Deviation_Result"] = dev_test["result"]

        results.append(result_row)
        processed_indices.append(idx)

    # Create DataFrame with results, using the indices of the processed rows
    if results:
        results_df = pd.DataFrame(results, index=processed_indices)
    else:
        results_df = pd.DataFrame()

    # Combine with original DataFrame
    combined_df = pd.concat([nodes_statistics_dataframe, results_df], axis=1)

    # Fill NaN values for the boolean significance column and cast to bool
    # This affects nodes that were not tested (e.g., root, leaves)
    if "Are_Features_Dependent" in combined_df.columns:
        combined_df["Are_Features_Dependent"] = combined_df[
            "Are_Features_Dependent"
        ].fillna(False)

    return combined_df
